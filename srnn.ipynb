{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importa bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Masking\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob('/mnt/d/dados_surdos/CSVs/dados_pessoa2_*.csv')\n",
    "\n",
    "dfs = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa features e label\n",
    "grouped = df.groupby(['word', 'repetition'])\n",
    "X_raw = []\n",
    "y_raw = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliza features com valores entre 0 e 1\n",
    "scaler = MinMaxScaler()\n",
    "landmark_cols = list(df.columns[:63])\n",
    "df[landmark_cols] = scaler.fit_transform(df[landmark_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepara lista com frames agrupadas por video\n",
    "for (word, rep), group in grouped:\n",
    "    sequence = group[landmark_cols].values\n",
    "    X_raw.append(sequence)\n",
    "    y_raw.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa em treino, teste e validação de forma estratificada\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.3, stratify=y_raw, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.285, stratify=y_temp, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Treino - {(len(X_train)/len(X_raw))*100}%\")\n",
    "print(f\"Teste - {(len(X_test)/len(X_raw))*100}%\")\n",
    "print(f\"Validacao - {(len(X_val)/len(X_raw))*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_raw é uma lista de sequências de frames, onde:\n",
    "\n",
    "- cada item da lista representa um vídeo.\n",
    "\n",
    "- cada vídeo é representado como um array 2D de shape (T, 63), onde:\n",
    "\n",
    "    - T = número de frames (time steps) do vídeo (varia de vídeo para vídeo)\n",
    "\n",
    "    - 63 = número de features por frame (21 pontos da mão × 3 coordenadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "max_len = max(len(seq) for seq in X_train) # define tamanho maximo das sequencias\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', dtype='float32')\n",
    "X_val = pad_sequences(X_val,   maxlen=max_len, padding='post', dtype='float32')\n",
    "X_test = pad_sequences(X_test,  maxlen=max_len, padding='post', dtype='float32')\n",
    "\n",
    "X_train.shape,X_val.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode das labels - OneHotEncoder\n",
    "label_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = label_encoder.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_val = label_encoder.transform(np.array(y_val).reshape(-1, 1))\n",
    "y_test = label_encoder.transform(np.array(y_test).reshape(-1, 1))\n",
    "\n",
    "y_train.shape,y_test.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 26 # palavras/labels\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Masking(mask_value=0.0, input_shape=(max_len, 63))\n",
    "SRNN = SimpleRNN(128)\n",
    "dense = Dense(num_classes, activation='softmax')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(mask)\n",
    "model.add(SRNN)\n",
    "model.add(dense)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\naccuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historico de treinamento\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
