{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Importa bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Masking, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Definições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "BASE_DIR = \"/mnt/d/videos_fatiados\"\n",
    "TARGET_SIZE = (64, 64)\n",
    "\n",
    "X_FILE = \"/mnt/d/X.npy\"\n",
    "Y_FILE = \"/mnt/d/y.npy\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history(history, timestamp):\n",
    "    with open(f'training_history/pkl/{timestamp}.pkl', 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "\n",
    "def load_video(path, max_frames=None, target_size=(64, 64)):\n",
    "    # Carrega vídeo como sequência de frames grayscale normalizados\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # preto e branco\n",
    "        frame = cv2.resize(frame, target_size)           # redimensiona\n",
    "        frame = frame.astype(\"float32\") / 255.0          # normaliza\n",
    "        frames.append(frame)\n",
    "        count += 1\n",
    "        if max_frames and count >= max_frames:\n",
    "            break\n",
    "    cap.release()\n",
    "    return np.array(frames)  # shape: (n_frames, H, W)\n",
    "\n",
    "\n",
    "def pad_and_flatten_sequences(X_raw, max_len, target_size=(64, 64)):\n",
    "    # Padroniza quantidade de frames e aplica flatten\n",
    "    H, W = target_size\n",
    "    flattened_dim = H * W\n",
    "    X_padded = np.zeros((len(X_raw), max_len, flattened_dim), dtype=\"float32\")\n",
    "\n",
    "    for i, seq in enumerate(X_raw):\n",
    "        seq_len = len(seq)\n",
    "        flat_seq = seq.reshape(seq_len, -1)  # (frames, H*W)\n",
    "        if seq_len <= max_len:\n",
    "            X_padded[i, :seq_len, :] = flat_seq\n",
    "        else:\n",
    "            X_padded[i, :, :] = flat_seq[:max_len, :]\n",
    "    return X_padded\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Carregando ou processando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando vídeos brutos...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m video_files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(full_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vf \u001b[38;5;129;01min\u001b[39;00m video_files:\n\u001b[0;32m---> 22\u001b[0m     frames \u001b[38;5;241m=\u001b[39m \u001b[43mload_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTARGET_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     X_raw\u001b[38;5;241m.\u001b[39mappend(frames)\n\u001b[1;32m     24\u001b[0m     y_raw\u001b[38;5;241m.\u001b[39mappend(label_dir)  \u001b[38;5;66;03m# usa o nome da pasta como rótulo\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m, in \u001b[0;36mload_video\u001b[0;34m(path, max_frames, target_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_video\u001b[39m(path, max_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Carrega vídeo como sequência de frames grayscale normalizados\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVideoCapture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m     count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if os.path.exists(X_FILE) and os.path.exists(Y_FILE):\n",
    "    print(\"Carregando dados pré-processados...\")\n",
    "    X = np.load(X_FILE)\n",
    "    y_raw = np.load(Y_FILE, allow_pickle=True)\n",
    "    max_len = X.shape[1]\n",
    "else:\n",
    "    print(\"Processando vídeos brutos...\")\n",
    "\n",
    "    X_raw = []\n",
    "    y_raw = []\n",
    "\n",
    "    # percorre os diretórios de 1 a 26\n",
    "    for label_dir in sorted(os.listdir(BASE_DIR), key=lambda x: int(x)):\n",
    "        full_dir = os.path.join(BASE_DIR, label_dir)\n",
    "        if not os.path.isdir(full_dir):\n",
    "            continue\n",
    "\n",
    "        # pega todos os vídeos dentro da pasta\n",
    "        video_files = glob.glob(os.path.join(full_dir, \"*.mp4\"))\n",
    "\n",
    "        for vf in video_files:\n",
    "            frames = load_video(vf, target_size=TARGET_SIZE)\n",
    "            X_raw.append(frames)\n",
    "            y_raw.append(label_dir)  # usa o nome da pasta como rótulo\n",
    "\n",
    "    max_len = max(len(seq) for seq in X_raw)\n",
    "    print(\"Número de vídeos:\", len(X_raw))\n",
    "    print(\"Maior quantidade de frames:\", max_len)\n",
    "\n",
    "    X = pad_and_flatten_sequences(X_raw, max_len, target_size=TARGET_SIZE)\n",
    "\n",
    "    # Salva fora da pasta videos_fatiados\n",
    "    np.save(X_FILE, X)\n",
    "    np.save(Y_FILE, np.array(y_raw, dtype=object))\n",
    "    print(f\"Dados salvos em {X_FILE} e {Y_FILE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 2\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=seed)\n",
    "all_fold_accuracies = []\n",
    "all_fold_losses = []\n",
    "histories = []\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_raw)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X), 1):\n",
    "    print(f\"\\n========== FOLD {fold} ==========\")\n",
    "\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y_encoded[train_index], y_encoded[val_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0.0, input_shape=(max_len, X.shape[2])))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = f'models/fold_{fold}_checkpoint.model.keras'\n",
    "    early_stop = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "    csv_logger = CSVLogger(f'training_log_fold_{fold}.csv')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=0.00001, verbose=1)\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=8,\n",
    "        epochs=50,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val),\n",
    "        shuffle=True,\n",
    "        callbacks=[csv_logger, reduce_lr, model_checkpoint_callback, early_stop]\n",
    "    )\n",
    "\n",
    "    histories.append(history)\n",
    "\n",
    "    best_model = load_model(checkpoint_filepath)\n",
    "    val_loss, val_accuracy = best_model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"FOLD {fold} - Accuracy: {val_accuracy:.4f}, Loss: {val_loss:.4f}\")\n",
    "\n",
    "    all_fold_accuracies.append(val_accuracy)\n",
    "    all_fold_losses.append(val_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n========== RESULTADOS FINAIS ==========\")\n",
    "for i, (acc, loss) in enumerate(zip(all_fold_accuracies, all_fold_losses), 1):\n",
    "    print(f\"Fold {i}: Accuracy = {acc:.4f}, Loss = {loss:.4f}\")\n",
    "print(f\"Média de acurácia: {np.mean(all_fold_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Gráficos de Acurácia e Loss por Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, history in enumerate(histories, 1):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Treino')\n",
    "    plt.plot(history.history['val_accuracy'], linestyle='--', label='Validação')\n",
    "    plt.title(f'Fold {i} - Acurácia')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Treino')\n",
    "    plt.plot(history.history['val_loss'], linestyle='--', label='Validação')\n",
    "    plt.title(f'Fold {i} - Loss')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
